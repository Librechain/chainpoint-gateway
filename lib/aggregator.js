/**
 * Copyright 2017 Tierion
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *     http://www.apache.org/licenses/LICENSE-2.0
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
*/

// load environment variables
const env = require('./parse-env.js')

const MerkleTools = require('merkle-tools')
const crypto = require('crypto')
const cpb = require('chainpoint-binary')
const _ = require('lodash')
const utils = require('./utils.js')
const uuidTime = require('uuid-time')
const coreHosts = require('./core-hosts.js')
const BLAKE2s = require('blake2s-js')

// The redis connection used for all redis communication
// This value is set once the connection has been established
let redis = null

// The key used to generate the HMAC for POST /hash and /proofs requests
let HMAC_KEY = null

// An array of hashes received awaiting aggregation
let HASHES = []

// An dictionary of objects containing hashes submitted to Core
// Each object contains a hash representing the merkle root of a Core aggregation
// as well as a proof data object containing the hashes making up the merkle tree,
// the corresponding hash_ids, and each hash's proof path to the root
let CORE_SUBMISSIONS = {}

// the aggregation frequency
let AGG_FOR_CORE_INTERVAL_MS = 1000

// the proof check frequency
let PROOF_CHECK_INTERVAL_MS = 10000

// The merkle tools object for building trees and generating proof paths
const merkleTools = new MerkleTools()

/**
 * Converts proof path array output from the merkle-tools package
 * to a Chainpoint v3 ops array
 *
 * @param {proof object array} proof - The proof array generated by merkle-tools
 * @param {string} op - The hash type performed throughout merkle tree construction (sha-256, sha-512, sha-256-x2, etc.)
 * @returns {ops object array}
 */
function formatAsChainpointV3Ops (proof, op) {
  proof = proof.map((item) => {
    if (item.left) {
      return { l: item.left }
    } else {
      return { r: item.right }
    }
  })
  let ChainpointV3Ops = []
  for (let x = 0; x < proof.length; x++) {
    ChainpointV3Ops.push(proof[x])
    ChainpointV3Ops.push({ op: op })
  }
  return ChainpointV3Ops
}

// Build a merkle tree from HASHES and submit the root to Core
async function aggregateAndSendToCoreAsync () {
  let hashesForTree = HASHES.splice(0)

  if (hashesForTree.length > 0) {
    console.log(`Building aggregation tree with ${hashesForTree.length} hash(es) for this interval`)

    // clear the merkleTools instance to prepare for a new tree
    merkleTools.resetTree()

    // concatenate and hash the hash ids and hash values into new array
    let leaves = hashesForTree.map((hashObj) => {
      let hashIdBuffer = Buffer.from(`node_id:${hashObj.hash_id_node}`, 'utf8')
      let hashBuffer = Buffer.from(hashObj.hash, 'hex')
      let concatAndHashBuffer = crypto.createHash('sha256').update(Buffer.concat([hashIdBuffer, hashBuffer])).digest()
      return concatAndHashBuffer
    })

    // Add every hash in hashesForTree to new Merkle tree
    merkleTools.addLeaves(leaves)
    merkleTools.makeTree()

    let treeSize = merkleTools.getLeafCount()

    // Collect and store the merkle root, and proofs in an array to be used for proof generation
    let coreAggregationData = {}
    coreAggregationData.merkle_root = merkleTools.getMerkleRoot().toString('hex')

    let proofData = []
    for (let x = 0; x < treeSize; x++) {
      // push the hash_id and corresponding proof onto the array, inserting the UUID concat/hash step at the beginning
      let proofDataItem = {}
      proofDataItem.hash_id = hashesForTree[x].hash_id_node
      proofDataItem.hash = hashesForTree[x].hash
      let partialProofPath = merkleTools.getProof(x)
      partialProofPath.unshift({ left: `node_id:${hashesForTree[x].hash_id_node}` })
      proofDataItem.partial_proof_path = formatAsChainpointV3Ops(partialProofPath, 'sha-256')
      proofData.push(proofDataItem)
    }
    coreAggregationData.proof_data = proofData

    // submit merkle root to Core
    try {
      let hash = crypto.createHmac('sha256', HMAC_KEY)
      let hmac = hash.update(env.NODE_TNT_ADDRESS).digest('hex')
      let submitResult = await submitHashToCoreAsync(coreAggregationData.merkle_root, hmac)

      // validate BLAKE2s
      let hashTimestampMS = parseInt(uuidTime.v1(submitResult.hash_id))
      let h = new BLAKE2s(5, { personalization: Buffer.from('CHAINPNT') })
      let hashStr = [
        hashTimestampMS.toString(),
        hashTimestampMS.toString().length,
        submitResult.hash,
        submitResult.hash.length,
        submitResult.nist,
        submitResult.nist.length
      ].join(':')
      h.update(Buffer.from(hashStr))
      let expectedData = Buffer.concat([Buffer.from([0x01]), h.digest()]).toString('hex')
      let embeddedData = submitResult.hash_id.slice(24)
      if (embeddedData !== expectedData) {
        throw new Error('Hash ID from Core refused: Cannot validate BLAKE2s embedded data')
      }

      coreAggregationData.processing_hints = submitResult.processing_hints
      coreAggregationData.hash_id_core = submitResult.hash_id
      coreAggregationData.anchorsComplete = []
      // store object for later use when generating proofs
      CORE_SUBMISSIONS[coreAggregationData.hash_id_core] = coreAggregationData
      console.log(`Hash submitted to Core: hash_id_core: ${coreAggregationData.hash_id_core} remaining credits: ${submitResult.tnt_credit_balance}`)
    } catch (error) {
      if (error.message === 'Bad NTP time') {
        console.error('Core NTP time not valid, resubmitting at next interval...')
        // put the hashes back into the head of the HASHES array, try again at next interval
        // TODO: long term Core NTP time issue may cause the HASHES array to grow unbounded
        // as new hashes come in, but existing ones are not successfully submitted, thus they
        // and not removed from HASHES, instead they are returned back to the HASHES array.
        // Do something about that.
        HASHES = hashesForTree.concat(HASHES)
      } else {
        console.error(`Could not submit hash to Core: ${error.message}`)
      }
    }
  }
}
// run aggregateToCore() at a regular interval
setInterval(aggregateAndSendToCoreAsync, AGG_FOR_CORE_INTERVAL_MS)

// check for proofs from Core for each hash in CORE_SUBMISSIONS
async function checkForProofsFromCoreAsync () {
  // assemble array of hashes ready to be checked for new proofs based on anchorsComplete and processing hints
  let hashIdsToCheck = []
  for (var hashIdCore in CORE_SUBMISSIONS) {
    if (CORE_SUBMISSIONS.hasOwnProperty(hashIdCore)) {
      let aggData = CORE_SUBMISSIONS[hashIdCore]
      // wait for recommended time before checking for btc proofs
      // TODO: Update this to account for eth
      if (aggData.anchorsComplete.length === 0) {
        // no anchors have been marked complete yet, must not yet have received initial calendar proof
        // add to check array to attempt to retrieve calendar proof
        hashIdsToCheck.push(hashIdCore)
      } else if (aggData.anchorsComplete.includes('cal') && !aggData.anchorsComplete.includes('btc')) {
        // a calendar proof has already been retrieved, but we are still awaiting the btc proof
        // if we are beyond the processing_hint time for btc, add to check array to attempt to retrieve btc proof
        let readyTime = Date.parse(aggData.processing_hints.btc)
        if (readyTime <= Date.now()) hashIdsToCheck.push(hashIdCore)
      }
    }
  }
  // split hashIdsToCheck into batches of 250, to honor max proof query limit
  // TODO: Read max proof query limit from stack's /config
  // TODO: delete any outstanding items with a UUID older than proof expire minutes
  let hashIdsToCheckBatches = []
  while (hashIdsToCheck.length > 0) {
    hashIdsToCheckBatches.push(hashIdsToCheck.splice(0, 250))
  }

  // iterate through each batch, checking for proofs from Core
  for (let x = 0; x < hashIdsToCheckBatches.length; x++) {
    let checkForProofResults = []
    try {
      checkForProofResults = await checkForProofsByHashIdsAsync(hashIdsToCheckBatches[x])
    } catch (error) {
      console.error(`Error querying for proofs on Core : ${error.message}`)
    }

    for (let y = 0; y < checkForProofResults.length; y++) {
      if (checkForProofResults[y].proof) {
        // a proof has been found for this hash_id
        // prepare full proofs by combining the proof with proof data
        let fullProofData = CORE_SUBMISSIONS[checkForProofResults[y].hash_id].proof_data.map((proofDataItem) => {
          let fullProofItem = {}
          fullProofItem.hash_id = proofDataItem.hash_id
          let fullProof = _.cloneDeep(checkForProofResults[y].proof)
          fullProof.hash_id_node = proofDataItem.hash_id
          fullProof.hash_submitted_node_at = utils.formatDateISO8601NoMs(new Date(parseInt(uuidTime.v1(fullProof.hash_id_node))))
          fullProof.hash = proofDataItem.hash
          for (let y = proofDataItem.partial_proof_path.length - 1; y >= 0; y--) {
            fullProof.branches[0].ops.unshift(proofDataItem.partial_proof_path[y])
          }
          fullProofItem.proof = fullProof
          return fullProofItem
        })

        for (let z = 0; z < fullProofData.length; z++) {
          // save each to redis
          let fullProofBase64 = cpb.objectToBase64Sync(fullProofData[z].proof)
          try {
            await redis.setAsync(fullProofData[z].hash_id, fullProofBase64, 'EX', env.PROOF_EXPIRE_MINUTES * 60)
          } catch (error) {
            console.error(`Could not save proof to Redis for  ${fullProofData[z].hash_id} : ${error.message}`)
          }
        }

        // update CORE_SUBMISSIONS object with latest anchorsComplete values
        CORE_SUBMISSIONS[checkForProofResults[y].hash_id].anchorsComplete = checkForProofResults[y].anchorsComplete
        // if all required anchors have been made, remove the item from CORE_SUBMISSIONS
        // TODO: update this when enabling eth
        if (checkForProofResults[y].anchorsComplete.includes('btc')) {
          // a proof including btc anchor has been returned, stop polling for this hash_id
          delete CORE_SUBMISSIONS[checkForProofResults[y].hash_id]
        }
      }
    }
  }
}
setInterval(checkForProofsFromCoreAsync, PROOF_CHECK_INTERVAL_MS)

async function submitHashToCoreAsync (hash, hmac) {
  let options = {
    headers: {
      'Content-Type': 'application/json',
      'tnt-address': env.NODE_TNT_ADDRESS
    },
    auth: {
      'bearer': hmac
    },
    method: 'POST',
    uri: `/hashes`,
    body: { hash: hash },
    json: true,
    gzip: true,
    resolveWithFullResponse: true
  }

  let response
  try {
    response = await coreHosts.coreRequestAsync(options)
  } catch (error) {
    // check for error as a result of Core NTP time being off
    if (error.statusCode === 500 && error.message === 'Bad NTP time') throw new Error('Bad NTP time')
    if (error.statusCode) throw new Error(`Invalid response : ${error.statusCode} : ${error.message}`)
    throw new Error(`No response received on POST hashes : ${error.message}`)
  }

  let result = {
    hash_id: response.hash_id,
    hash: response.hash,
    nist: response.nist,
    processing_hints: response.processing_hints,
    tnt_credit_balance: response.tnt_credit_balance
  }
  return result
}

async function checkForProofsByHashIdsAsync (hashIdArray) {
  let hashIdCSV = hashIdArray.join(',')
  let options = {
    headers: {
      'Content-Type': 'application/json',
      hashids: hashIdCSV
    },
    method: 'GET',
    uri: `/proofs`,
    json: true,
    gzip: true,
    resolveWithFullResponse: true
  }

  let response
  try {
    response = await coreHosts.coreRequestAsync(options)
  } catch (error) {
    if (error.statusCode) throw new Error(`Invalid response : ${error.statusCode} : ${error.message}`)
    throw new Error(`No response received on GET proof : ${error.message}`)
  }

  let proofCheckResults = []

  for (let x = 0; x < response.length; x++) {
    let hashItem = response[x]
    if (hashItem.proof === null) {
      proofCheckResults.push({ hash_id: hashItem.hash_id, proof: null })
    } else {
      let proofObject = null
      try {
        proofObject = cpb.binaryToObjectSync(hashItem.proof)
      } catch (err) {
        proofCheckResults.push({ hash_id: hashItem.hash_id, proof: '' })
      }
      if (proofObject) {
        // a proof has been returned
        // Identify the anchors completed in this proof
        let anchorsComplete = utils.parseAnchorsComplete(proofObject)
        proofCheckResults.push({ hash_id: hashItem.hash_id, proof: proofObject, anchorsComplete: anchorsComplete })
      }
    }
  }

  return proofCheckResults
}

module.exports = {
  addHashes: (hashArray) => { HASHES = HASHES.concat(hashArray) },
  setRedis: (redisClient) => {
    coreHosts.setRedis(redisClient)
    redis = redisClient
  },
  setHmacKey: (hmacKey) => { HMAC_KEY = hmacKey }
}
